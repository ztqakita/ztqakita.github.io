<!doctype html><html><head><title>[CN] Continuous-attractor Neural Network</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/navigators/navbar.css><link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css><link rel=icon type=image/png href=/images/favicon_hu8376fd15465fef26ffe66b6bcf0ca686_13669_42x0_resize_box_2.png><link rel=stylesheet href=/css/style.css><meta name=description content="[CN] Continuous-attractor Neural Network"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/><img src=/images/main-logo_hu864bbe108f1be1ae04b57f7f2fd9d631_5637_42x0_resize_box_2.png>ztqakita's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"></ul></div></div><img src=/images/main-logo_hu864bbe108f1be1ae04b57f7f2fd9d631_5637_42x0_resize_box_2.png class=d-none id=main-logo>
<img src=/images/inverted-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_42x0_resize_box_2.png class=d-none id=inverted-logo></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=https://ztqakita.github.io/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts data-filter=all>Posts</a></li><div class=subtree><li><a href=/posts/introduction/>Introduction</a></li><li><i class="fas fa-plus-circle"></i><a href=/posts/algorithms/>Algorithms</a><ul><li><a href=/posts/algorithms/algorithm_analysis-1/>Complexity & Divide and Conquer</a></li><li><a href=/posts/algorithms/algorithm_analysis-2/>Dynamic Programming</a></li><li><a href=/posts/algorithms/algorithm_analysis-3/>Greedy & Back-track & Branch and Bound</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/compiler/>Compiler</a><ul><li><a href=/posts/compiler/compilers_1/>Lexcial Analysis & Parsing</a></li><li><a href=/posts/compiler/compilers_3/>Semantic Analysis & Runtime Environment</a></li><li><a href=/posts/compiler/compilers_2/>Syntax-directed Translation</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/neural-computation/>Computational Neuroscience</a><ul><li><a href=/posts/neural-computation/1-ionic_currents/>Ionic Currents</a></li><li><a href=/posts/neural-computation/basic-neuro-knowledge/>Neuroscience Basic Knowledge</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/database-system/>Database System</a><ul><li><a href=/posts/database-system/database_system_1/>Database System Lecture Note 1</a></li><li><a href=/posts/database-system/database_system_2/>Database System Lecture Note 2</a></li><li><a href=/posts/database-system/database_system_3/>Database System Lecture Note 3</a></li><li><a href=/posts/database-system/database_system_4/>Database System Lecture Note 4</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/deep-learning/>DL</a><ul><li><a href=/posts/deep-learning/cnn/>Convolutional Neural Network</a></li><li><a href=/posts/deep-learning/introduction-to-deep-learning/>Introduction to Deep Learning</a></li><li><a href=/posts/deep-learning/optimizer-for-dl/>Optimization for Deep Learning</a></li><li><a href=/posts/deep-learning/rnn/>Recursive Neural Network</a></li><li><a href=/posts/deep-learning/self-attention/>Self-attention</a></li><li><a href=/posts/deep-learning/transformer/>Transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/life-learning/>Life Learning</a><ul><li><a href=/posts/life-learning/architectures_of_neuronal_circuits/>Architectures of neuronal circuits</a></li><li><a href=/posts/life-learning/how_to_model/>how to model</a></li><li><a href=/posts/life-learning/lecture_james_mcclleland/>Lecture James McClleland</a></li><li><a href=/posts/life-learning/lecture_yao_xin/>Lecture Yao Xin</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/machine-learning/>ML</a><ul><li><a href=/posts/machine-learning/basic-concepts/>Basic Concepts</a></li><li><a href=/posts/machine-learning/classification/>Classification</a></li><li><a href=/posts/machine-learning/decision-tree/>Decision Tree</a></li><li><a href=/posts/machine-learning/knn/>KNN</a></li><li><a href=/posts/machine-learning/perceptron/>Perceptron</a></li><li><a href=/posts/machine-learning/som/>SOM</a></li><li><a href=/posts/machine-learning/support-vector/>Support Vector Machines</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/operating-system/>Operating System</a><ul><li><a href=/posts/operating-system/operating_system_concepts_3/>CPU Scheduling</a></li><li><a href=/posts/operating-system/operating_system_concepts_6/>File System</a></li><li><a href=/posts/operating-system/operating_system_concepts_1/>Introduction & OS Structure</a></li><li><a href=/posts/operating-system/operating_system_concepts_7/>Mass-Storage Structure & I/O System</a></li><li><a href=/posts/operating-system/operating_system_concepts_5/>Memory Management</a></li><li><a href=/posts/operating-system/operating_system_concepts_2/>Process & Threads</a></li><li><a href=/posts/operating-system/operating_system_concepts_4/>Process Synchronization</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/posts/paper-reading/>Paper Reading</a><ul class=active><li><a class=active href=/posts/paper-reading/continuous_attractor_nn/>Continuous-attractor Neural Network</a></li><li><a href=/posts/paper-reading/few-shot_class_incremental_learning/>Few-Shot Class-Incremental Learning</a></li><li><a href=/posts/paper-reading/integrated_understanding_system/>Integrated understanding system</a></li><li><a href=/posts/paper-reading/push-pull_feedback/>Push-pull feedback</a></li><li><a href=/posts/paper-reading/reservoir_decision_making/>reservoir decision making network</a></li><li><a href=/posts/paper-reading/task_representation_cognitive_tasks/>Task representations in neural networks</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(https://ztqakita.github.io/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/ztq.png><h5 class=author-name>Brandon Zhang</h5><p>August 30, 2021</p></div><div class=title><h1>[CN] Continuous-attractor Neural Network</h1></div><div class=post-content id=post-content><blockquote><p>Si Wu, Kosuke Hamaguchi, and Shun-ichi Amari. “Dynamics and computation of continuous attractors.” Neural computation 20.4 (2008): 994-1025.</p></blockquote><p>本篇参考吴思老师公众号的文章《【学术思想】连续吸引子神经网络：神经信息表达的正则化网络模型》，并根据冷泉港亚洲暑期学校的讲座和智源学术沙龙的报告来详细阐释CANN的工作原理，全文用中文行文。</p><h2 id=连续吸引子神经网络的数学模型>连续吸引子神经网络的数学模型</h2><p>吸引子指的是一个动力学系统在不接受外界输入情况下靠自身动力学就能维持的非静息的稳定状态（active stationary state）。要构成一个的吸引子网络，需要两个基本条件：</p><ol><li>神经元之间有<strong>兴奋性的互馈连接</strong> (recurrent connection)，这样在没有外界输入的情况下，靠神经元之间的正反馈，网络就能维持住稳定活动；同时我们也要求兴奋性连接是局部的，这样才能形成有意义的空间局部活动；</li><li>网络中要有<strong>抑制性作用</strong>，这样才能避免系统活动因反复的正反馈而爆炸。</li></ol><blockquote><p>Hopfield模型采用吸引子的思想解释了大脑在收到部分或模糊信息条件下的联想式记忆机制。但经典的Hopfield模型没有考虑神经元之间连接的对称结构，因而其具有的吸引子（多个）在空间上是相互孤立的。</p></blockquote><p>在吸引子网络的基础上，如果我们进一步要求神经元之间的连接<strong>具有空间平移不变性的对称结构</strong>，这时网络就将具有一簇连续的、而不是孤立的吸引子（注意，考虑到真实生物系统的神经数目足够大，为了方便，后面讨论都假设神经元数目是无穷的）；这些吸引子在参数空间上紧密排列，构成一个<strong>连续的状态子空间</strong>。</p><p><img src=/images/posts/paper/6.JPG alt></p><h3 id=一维cann数学模型>一维CANN数学模型</h3><p>神经元的突触总输入$u$的动力学方程如下：
$$
\tau \, \frac{du(x, t)}{dt} = -u(x,t) + \rho \int dx' J(x,x')\, r(x',t) + I_{ext}
$$
其中$x$表示神经元的参数空间位点，$u(x)$代表在参数空间位点x上的神经元的突触总输入，$r(x^′​,t)$为神经元($x'$)的发放率，由以下公式给出:
$$
r(x,t) = \frac{u(x,t)^2}{1+k\rho\int{dx&rsquo;u(x',t)^2}}
$$
该模型没有单独考虑抑制性神经元，而是将其作用效果包含在除法归一化作用中。而神经元($x$)和($x'$)之间的兴奋性连接强度$J(x, x')$由高斯函数给出:
$$
J(X,x') = \frac{1}{\sqrt{2\pi} \alpha} \, exp\left( - \frac{|x-x'|^2}{2\alpha^2}\right)
$$
我们看到其具有平移不变性，即其为$(x-x’)$的函数。外界输入$I_{ext}$与位置$z(t)$有关，公式如下：
$$
I_{ext}=A \, exp \left[ - \frac{|x-z(t)|^2}{4\alpha^2}\right]
$$</p><p>这个模型在数学上有精准解，使得我们可以对其动力学做细致的理论分析，从而更容易理解其计算功能，并将其用于神经建模中。</p><h2 id=cann的动力学性质>CANN的动力学性质</h2><p>考虑一维参数空间x是一个周期变量，如朝向、运动方向、头朝向等。一个一维的CANN具有<strong>一簇高斯波包的稳定状态</strong>（图1C），它们在系统状态空间中构成一个<strong>一维的能量平滑的子空间</strong>（近似）（图1B）。在这个子空间上，因为能量函数是平的，系统状态处于<strong>随遇平衡</strong>(neutral stability)；这意味着在外部微小输入的驱动下，系统可以轻松改变状态。注意这个性质是其它非连续吸引子网络（如Hopfield网络）所不具有的（图1A）。这个随遇平衡是CANN动力学的关键，它使得网络状态能够平滑跟踪外部运动输入，从而实现了多项计算功能，如编码头朝向编码和空间位置等。</p><h2 id=cann的计算性质>CANN的计算性质</h2><h4 id=1-神经元群编码>1. 神经元群编码</h4><p>实验发现，对于很多类型的刺激，尤其是连续变量（如角度、空间位置等），神经系统的编码策略为：一大群神经元共同协作编码刺激值，其中每个神经元的反应覆盖一定范围的刺激值，且对某个特定值产生最大反应（表现为高斯形状的调谐函数）；神经元群的调谐函数覆盖整个参数空间。</p><p><img src=/images/posts/paper/7.JPG alt></p><p>CANN实现优化的神经元群编码。在接受外部有噪声的输入后，网络状态（波包）会快速移动到一个位置，使得波包和噪声输入的重叠最大，相当于一个template matching的操作，波包的顶点位置即为解码结果。</p><h4 id=2预测跟踪>2、预测跟踪</h4><p>为了实现预测跟踪，我们研究发现，如果在神经元动力学中引入神经系统广泛存在的<strong>负反馈机制</strong>（其可以是单个神经元发放强度的自适应（spike frequency adaptation）（图5A）、神经元之间突触的<strong>短时程衰减</strong>(short-term plasticity)、或者不同层间的反馈抑制等），那么CANN就可以实现时间上恒定领先的运动预测跟踪（图5B）。我们首先发现在引入互反馈机制后，CANN能维持一个<strong>行波解</strong>(travelling wave)，且行波的速度（网络的内在速度）由负反馈强度调制。在接受运动输入的情况下，网络中波包移动速度被锁定到输入的运动速度，但其空间位置是领先还是落后于目标位置则是由网络内在速度与目标运动速度的相对大小来决定的（图5C）：当内在速度大于目标运动速度时，预测就发生了。</p><p><img src=/images/posts/paper/8.JPG alt></p><p>CANN的这种强大预测跟踪能力也为我们提供了一种类脑的运动目标跟踪算法。该算法的优点包括：</p><ol><li>预测跟踪的时间是恒定的，几乎不依赖于目标运动速度；</li><li>模型的参数是可以根据任务，理论上预先设定的，不需要网络训练；</li><li>CANN及反馈机制可以被类脑芯片实现。</li></ol><p>在这里对CANN with Adaptation模型简要地阐述：
$$
\begin{align*}
\<br>&\tau \, \frac{du(x, t)}{dt} = -u(x,t) + \rho \int dx' J(x,x')\, r(x',t) - V(x,t) + I_{ext} \\<br>\\<br>&\tau_v \, \frac{dV(x,t)}{dt} = - V(x,t) + m\,U(x,t)\<br>\<br>\end{align*}
$$</p><p><img src=/images/posts/paper/10.JPG alt></p><h4 id=3多模态信息整合>3、多模态信息整合</h4><p>从计算的角度看，在整合这些不同属性或特征的信号时，大脑需要一种共同的信息表达模式，才能相互交流信息。CANN，在其中信息被统一表达为神经群活动波包，为多模态信息整合提供了一种可能的操作平台。我们研究了视觉和平衡觉信息整合来感知头朝向(heading direction)的神经网络模型。依据实验数据，我们提出了去中心化的计算模型，其中<strong>MSTd上的CANN主要接受视觉信号</strong>，而<strong>VIP上的CANN主要接受平衡觉信号</strong>，两者之间通过长程连接交换信息（图6）。我们的研究表明两个耦合的CANN能够可以实现贝叶斯优化信息整合，也可以实现统计优化的信息分离，初步支持了CANN可以作为大脑内信息表达、储存、运算、和交流的统一网络框架。</p><p><img src=/images/posts/paper/9.JPG alt>
图6：CANN实现优化的多模态信息整合。A，去中心化的信息整合网络结构示意图。B，两个耦合的CANN，分别接受视觉和平衡觉信号，共同计算自身运动的方向。C和D，网络计算结果和统计优化的贝叶斯理论符合。</p><h2 id=总结>总结</h2><p>在讲座中老师还提到了很多前景和应用，在这里我简单罗列一下：</p><ul><li>Levy Flight in CANN: Levy FLight是一种运动模式，可以与布朗运动类比，其特点是一段小范围的随机游走后会进行一次距离较大的转移，这种特性和大脑联想记忆机制很相似。而CANN在tracking上根据内在速度和目标速度的三种关系（小于、等于、大于）分成了三种tracking模式，其中一种Oscillation tracking模式，这种模式和联合记忆机制有着很大的关联，这一话题会在后续和老师交流以后单独写一个博客讲解。</li><li>Phase pre- and pro-cession with CANN: to be continue</li></ul><h2 id=cann代码>CANN代码</h2><blockquote><p>source: BrainModel from PKU-NIP-LAB</p></blockquote><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> numpy <span style=color:#f92672>as</span> np
<span style=color:#f92672>import</span> brainpy <span style=color:#f92672>as</span> bp


<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CANN1D</span>(bp<span style=color:#f92672>.</span>NeuGroup):
    target_backend <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;numpy&#39;</span>, <span style=color:#e6db74>&#39;numba&#39;</span>]

    <span style=color:#a6e22e>@staticmethod</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>derivative</span>(u, t, conn, k, tau, Iext):
        r1 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>square(u)
        r2 <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span> <span style=color:#f92672>+</span> k <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum(r1)
        r <span style=color:#f92672>=</span> r1 <span style=color:#f92672>/</span> r2
        Irec <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(conn, r)
        du <span style=color:#f92672>=</span> (<span style=color:#f92672>-</span>u <span style=color:#f92672>+</span> Irec <span style=color:#f92672>+</span> Iext) <span style=color:#f92672>/</span> tau
        <span style=color:#66d9ef>return</span> du

    <span style=color:#66d9ef>def</span> __init__(self, num, tau<span style=color:#f92672>=</span><span style=color:#ae81ff>1.</span>, k<span style=color:#f92672>=</span><span style=color:#ae81ff>8.1</span>, a<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, A<span style=color:#f92672>=</span><span style=color:#ae81ff>10.</span>, J0<span style=color:#f92672>=</span><span style=color:#ae81ff>4.</span>,
                 z_min<span style=color:#f92672>=-</span>np<span style=color:#f92672>.</span>pi, z_max<span style=color:#f92672>=</span>np<span style=color:#f92672>.</span>pi, <span style=color:#f92672>**</span>kwargs):
        <span style=color:#75715e># parameters</span>
        self<span style=color:#f92672>.</span>tau <span style=color:#f92672>=</span> tau  <span style=color:#75715e># The synaptic time constant</span>
        self<span style=color:#f92672>.</span>k <span style=color:#f92672>=</span> k  <span style=color:#75715e># Degree of the rescaled inhibition</span>
        self<span style=color:#f92672>.</span>a <span style=color:#f92672>=</span> a  <span style=color:#75715e># Half-width of the range of excitatory connections</span>
        self<span style=color:#f92672>.</span>A <span style=color:#f92672>=</span> A  <span style=color:#75715e># Magnitude of the external input</span>
        self<span style=color:#f92672>.</span>J0 <span style=color:#f92672>=</span> J0  <span style=color:#75715e># maximum connection value</span>

        <span style=color:#75715e># feature space</span>
        self<span style=color:#f92672>.</span>z_min <span style=color:#f92672>=</span> z_min
        self<span style=color:#f92672>.</span>z_max <span style=color:#f92672>=</span> z_max
        self<span style=color:#f92672>.</span>z_range <span style=color:#f92672>=</span> z_max <span style=color:#f92672>-</span> z_min
        self<span style=color:#f92672>.</span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linspace(z_min, z_max, num)  <span style=color:#75715e># The encoded feature values</span>

        <span style=color:#75715e># variables</span>
        self<span style=color:#f92672>.</span>u <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(num)
        self<span style=color:#f92672>.</span>input <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(num)

        <span style=color:#75715e># The connection matrix</span>
        self<span style=color:#f92672>.</span>conn_mat <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>make_conn(self<span style=color:#f92672>.</span>x)

        self<span style=color:#f92672>.</span>int_u <span style=color:#f92672>=</span> bp<span style=color:#f92672>.</span>odeint(f<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>derivative, method<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rk4&#39;</span>, dt<span style=color:#f92672>=</span><span style=color:#ae81ff>0.05</span>)

        super(CANN1D, self)<span style=color:#f92672>.</span>__init__(size<span style=color:#f92672>=</span>num, <span style=color:#f92672>**</span>kwargs)

        self<span style=color:#f92672>.</span>rho <span style=color:#f92672>=</span> num <span style=color:#f92672>/</span> self<span style=color:#f92672>.</span>z_range  <span style=color:#75715e># The neural density</span>
        self<span style=color:#f92672>.</span>dx <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>z_range <span style=color:#f92672>/</span> num  <span style=color:#75715e># The stimulus density</span>

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>dist</span>(self, d):
        d <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>remainder(d, self<span style=color:#f92672>.</span>z_range)
        d <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>where(d <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.5</span> <span style=color:#f92672>*</span> self<span style=color:#f92672>.</span>z_range, d <span style=color:#f92672>-</span> self<span style=color:#f92672>.</span>z_range, d)
        <span style=color:#66d9ef>return</span> d

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>make_conn</span>(self, x):
        <span style=color:#66d9ef>assert</span> np<span style=color:#f92672>.</span>ndim(x) <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>
        x_left <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>reshape(x, (<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>))
        x_right <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>repeat(x<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)), len(x), axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
        d <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dist(x_left <span style=color:#f92672>-</span> x_right)
        Jxx <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>J0 <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>exp(<span style=color:#f92672>-</span><span style=color:#ae81ff>0.5</span> <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>square(d <span style=color:#f92672>/</span> self<span style=color:#f92672>.</span>a)) <span style=color:#f92672>/</span> (np<span style=color:#f92672>.</span>sqrt(<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>pi) <span style=color:#f92672>*</span> self<span style=color:#f92672>.</span>a)
        <span style=color:#66d9ef>return</span> Jxx

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_stimulus_by_pos</span>(self, pos):
        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>A <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>exp(<span style=color:#f92672>-</span><span style=color:#ae81ff>0.25</span> <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>square(self<span style=color:#f92672>.</span>dist(self<span style=color:#f92672>.</span>x <span style=color:#f92672>-</span> pos) <span style=color:#f92672>/</span> self<span style=color:#f92672>.</span>a))

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>update</span>(self, _t):
        self<span style=color:#f92672>.</span>u <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>int_u(self<span style=color:#f92672>.</span>u, _t, self<span style=color:#f92672>.</span>conn_mat, self<span style=color:#f92672>.</span>k, self<span style=color:#f92672>.</span>tau, self<span style=color:#f92672>.</span>input)
        self<span style=color:#f92672>.</span>input[:] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.</span>

</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># population encoding</span>
cann <span style=color:#f92672>=</span> CANN1D(num<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>, k<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>, monitors<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;u&#39;</span>])

I1 <span style=color:#f92672>=</span> cann<span style=color:#f92672>.</span>get_stimulus_by_pos(<span style=color:#ae81ff>0.</span>)
Iext, duration <span style=color:#f92672>=</span> bp<span style=color:#f92672>.</span>inputs<span style=color:#f92672>.</span>constant_current([(<span style=color:#ae81ff>0.</span>, <span style=color:#ae81ff>1.</span>), (I1, <span style=color:#ae81ff>8.</span>), (<span style=color:#ae81ff>0.</span>, <span style=color:#ae81ff>8.</span>)])
cann<span style=color:#f92672>.</span>run(duration<span style=color:#f92672>=</span>duration, inputs<span style=color:#f92672>=</span>(<span style=color:#e6db74>&#39;input&#39;</span>, Iext))

bp<span style=color:#f92672>.</span>visualize<span style=color:#f92672>.</span>animate_1D(
    dynamical_vars<span style=color:#f92672>=</span>[{<span style=color:#e6db74>&#39;ys&#39;</span>: cann<span style=color:#f92672>.</span>mon<span style=color:#f92672>.</span>u, <span style=color:#e6db74>&#39;xs&#39;</span>: cann<span style=color:#f92672>.</span>x, <span style=color:#e6db74>&#39;legend&#39;</span>: <span style=color:#e6db74>&#39;u&#39;</span>},
                    {<span style=color:#e6db74>&#39;ys&#39;</span>: Iext, <span style=color:#e6db74>&#39;xs&#39;</span>: cann<span style=color:#f92672>.</span>x, <span style=color:#e6db74>&#39;legend&#39;</span>: <span style=color:#e6db74>&#39;Iext&#39;</span>}],
    frame_step<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,
    frame_delay<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,
    show<span style=color:#f92672>=</span>True,
    <span style=color:#75715e># save_path=&#39;../../images/CANN-encoding.gif&#39;</span>
)
</code></pre></div><p><img src=/images/posts/paper/CANN-encoding.gif alt></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># template matching</span>

cann <span style=color:#f92672>=</span> CANN1D(num<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>, k<span style=color:#f92672>=</span><span style=color:#ae81ff>8.1</span>, monitors<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;u&#39;</span>])

dur1, dur2, dur3 <span style=color:#f92672>=</span> <span style=color:#ae81ff>10.</span>, <span style=color:#ae81ff>30.</span>, <span style=color:#ae81ff>0.</span>
num1 <span style=color:#f92672>=</span> int(dur1 <span style=color:#f92672>/</span> bp<span style=color:#f92672>.</span>ops<span style=color:#f92672>.</span>get_dt())
num2 <span style=color:#f92672>=</span> int(dur2 <span style=color:#f92672>/</span> bp<span style=color:#f92672>.</span>ops<span style=color:#f92672>.</span>get_dt())
num3 <span style=color:#f92672>=</span> int(dur3 <span style=color:#f92672>/</span> bp<span style=color:#f92672>.</span>ops<span style=color:#f92672>.</span>get_dt())
Iext <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((num1 <span style=color:#f92672>+</span> num2 <span style=color:#f92672>+</span> num3,) <span style=color:#f92672>+</span> cann<span style=color:#f92672>.</span>size)
Iext[:num1] <span style=color:#f92672>=</span> cann<span style=color:#f92672>.</span>get_stimulus_by_pos(<span style=color:#ae81ff>0.5</span>)
Iext[num1:num1 <span style=color:#f92672>+</span> num2] <span style=color:#f92672>=</span> cann<span style=color:#f92672>.</span>get_stimulus_by_pos(<span style=color:#ae81ff>0.</span>)
Iext[num1:num1 <span style=color:#f92672>+</span> num2] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>0.1</span> <span style=color:#f92672>*</span> cann<span style=color:#f92672>.</span>A <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randn(num2, <span style=color:#f92672>*</span>cann<span style=color:#f92672>.</span>size)
cann<span style=color:#f92672>.</span>run(duration<span style=color:#f92672>=</span>dur1 <span style=color:#f92672>+</span> dur2 <span style=color:#f92672>+</span> dur3, inputs<span style=color:#f92672>=</span>(<span style=color:#e6db74>&#39;input&#39;</span>, Iext))

bp<span style=color:#f92672>.</span>visualize<span style=color:#f92672>.</span>animate_1D(
    dynamical_vars<span style=color:#f92672>=</span>[{<span style=color:#e6db74>&#39;ys&#39;</span>: cann<span style=color:#f92672>.</span>mon<span style=color:#f92672>.</span>u, <span style=color:#e6db74>&#39;xs&#39;</span>: cann<span style=color:#f92672>.</span>x, <span style=color:#e6db74>&#39;legend&#39;</span>: <span style=color:#e6db74>&#39;u&#39;</span>},
                    {<span style=color:#e6db74>&#39;ys&#39;</span>: Iext, <span style=color:#e6db74>&#39;xs&#39;</span>: cann<span style=color:#f92672>.</span>x, <span style=color:#e6db74>&#39;legend&#39;</span>: <span style=color:#e6db74>&#39;Iext&#39;</span>}],
    frame_step<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>,
    frame_delay<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>,
    show<span style=color:#f92672>=</span>True,
    <span style=color:#75715e># save_path=&#39;../../images/CANN-decoding.gif&#39;</span>
)
</code></pre></div><p><img src=/images/posts/paper/CANN-decoding.gif alt></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># smooth tracking</span>

cann <span style=color:#f92672>=</span> CANN1D(num<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>, k<span style=color:#f92672>=</span><span style=color:#ae81ff>8.1</span>, monitors<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;u&#39;</span>])

dur1, dur2, dur3 <span style=color:#f92672>=</span> <span style=color:#ae81ff>20.</span>, <span style=color:#ae81ff>20.</span>, <span style=color:#ae81ff>20.</span>
num1 <span style=color:#f92672>=</span> int(dur1 <span style=color:#f92672>/</span> bp<span style=color:#f92672>.</span>ops<span style=color:#f92672>.</span>get_dt())
num2 <span style=color:#f92672>=</span> int(dur2 <span style=color:#f92672>/</span> bp<span style=color:#f92672>.</span>ops<span style=color:#f92672>.</span>get_dt())
num3 <span style=color:#f92672>=</span> int(dur3 <span style=color:#f92672>/</span> bp<span style=color:#f92672>.</span>ops<span style=color:#f92672>.</span>get_dt())
position <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(num1 <span style=color:#f92672>+</span> num2 <span style=color:#f92672>+</span> num3)
position[num1: num1 <span style=color:#f92672>+</span> num2] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0.</span>, <span style=color:#ae81ff>12.</span>, num2)
position[num1 <span style=color:#f92672>+</span> num2:] <span style=color:#f92672>=</span> <span style=color:#ae81ff>12.</span>
position <span style=color:#f92672>=</span> position<span style=color:#f92672>.</span>reshape((<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>))
Iext <span style=color:#f92672>=</span> cann<span style=color:#f92672>.</span>get_stimulus_by_pos(position)
cann<span style=color:#f92672>.</span>run(duration<span style=color:#f92672>=</span>dur1 <span style=color:#f92672>+</span> dur2 <span style=color:#f92672>+</span> dur3, inputs<span style=color:#f92672>=</span>(<span style=color:#e6db74>&#39;input&#39;</span>, Iext))

bp<span style=color:#f92672>.</span>visualize<span style=color:#f92672>.</span>animate_1D(
    dynamical_vars<span style=color:#f92672>=</span>[{<span style=color:#e6db74>&#39;ys&#39;</span>: cann<span style=color:#f92672>.</span>mon<span style=color:#f92672>.</span>u, <span style=color:#e6db74>&#39;xs&#39;</span>: cann<span style=color:#f92672>.</span>x, <span style=color:#e6db74>&#39;legend&#39;</span>: <span style=color:#e6db74>&#39;u&#39;</span>},
                    {<span style=color:#e6db74>&#39;ys&#39;</span>: Iext, <span style=color:#e6db74>&#39;xs&#39;</span>: cann<span style=color:#f92672>.</span>x, <span style=color:#e6db74>&#39;legend&#39;</span>: <span style=color:#e6db74>&#39;Iext&#39;</span>}],
    frame_step<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>,
    frame_delay<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>,
    show<span style=color:#f92672>=</span>True,
    <span style=color:#75715e># save_path=&#39;../../images/CANN-tracking.gif&#39;</span>
)
</code></pre></div><p><img src=/images/posts/paper/CANN-tracking.gif alt></p></div><div class=btn-improve-page><a href=https://github.com/ztqakita/ztqakita.github.io/edit//content/posts/paper-reading/continuous_attractor_nn.md><i class="fas fa-code-branch"></i>Improve this page</a></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/life-learning/architectures_of_neuronal_circuits/ class="btn btn-outline-info"><span><i class="fas fa-chevron-circle-left"></i>Prev</span><br><span>Architectures of neuronal circuits</span></a></div><div class="col-md-6 next-article"><a href=/posts/life-learning/how_to_model/ class="btn btn-outline-info"><span>Next <i class="fas fa-chevron-circle-right"></i></span><br><span>Approaching Scientific Question & How to Model</span></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#连续吸引子神经网络的数学模型>连续吸引子神经网络的数学模型</a><ul><li><a href=#一维cann数学模型>一维CANN数学模型</a></li></ul></li><li><a href=#cann的动力学性质>CANN的动力学性质</a></li><li><a href=#cann的计算性质>CANN的计算性质</a><ul><li><ul><li><a href=#1-神经元群编码>1. 神经元群编码</a></li><li><a href=#2预测跟踪>2、预测跟踪</a></li><li><a href=#3多模态信息整合>3、多模态信息整合</a></li></ul></li></ul></li><li><a href=#总结>总结</a></li><li><a href=#cann代码>CANN代码</a></li></ul></nav></div></div></section></div><footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=#about>About</a></li><li class=nav-item><a class=smooth-scroll href=#skills>Skills</a></li><li class=nav-item><a class=smooth-scroll href=#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=#achievements>Achievements</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><span>Email:</span> <span>ztqakita@163.com</span></li><li><span>Phone:</span> <span>(+86)18618180071</span></li></ul></div><div class="col-md-4 col-sm-12"><p>Stay up to date with email notification</p><form><div class=form-group><input type=email class=form-control id=exampleInputEmail1 aria-describedby=emailHelp placeholder="Enter email">
<small id=emailHelp class="form-text text-muted">By entering your email address, you agree to receive the newsletter of this website.</small></div><button type=submit class="btn btn-info">Submit</button></form></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=#><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png>
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/js/jquery-3.4.1.min.js></script><script src=/js/popper.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/navbar.js></script><script src=/js/main.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad()</script><script type=text/javascript async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></body></html>
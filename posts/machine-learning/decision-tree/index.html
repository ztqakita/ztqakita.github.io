<!doctype html><html><head><title>Decision Tree</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/navigators/navbar.css><link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css><link rel=icon type=image/png href=/images/favicon_hu8376fd15465fef26ffe66b6bcf0ca686_13669_42x0_resize_box_2.png><link rel=stylesheet href=/css/style.css><meta name=description content="Decision Tree"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/><img src=/images/main-logo_hu864bbe108f1be1ae04b57f7f2fd9d631_5637_42x0_resize_box_2.png>ztqakita's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"></ul></div></div><img src=/images/main-logo_hu864bbe108f1be1ae04b57f7f2fd9d631_5637_42x0_resize_box_2.png class=d-none id=main-logo>
<img src=/images/inverted-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_42x0_resize_box_2.png class=d-none id=inverted-logo></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=https://ztqakita.github.io/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts data-filter=all>Posts</a></li><div class=subtree><li><a href=/posts/introduction/>Introduction</a></li><li><i class="fas fa-plus-circle"></i><a href=/posts/algorithms/>Algorithms</a><ul><li><a href=/posts/algorithms/algorithm_analysis-1/>Complexity & Divide and Conquer</a></li><li><a href=/posts/algorithms/algorithm_analysis-2/>Dynamic Programming</a></li><li><a href=/posts/algorithms/algorithm_analysis-3/>Greedy & Back-track & Branch and Bound</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/compiler/>Compiler</a><ul><li><a href=/posts/compiler/compilers_1/>Lexcial Analysis & Parsing</a></li><li><a href=/posts/compiler/compilers_3/>Semantic Analysis & Runtime Environment</a></li><li><a href=/posts/compiler/compilers_2/>Syntax-directed Translation</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/neural-computation/>Computational Neuroscience</a><ul><li><a href=/posts/neural-computation/1-ionic_currents/>Ionic Currents</a></li><li><a href=/posts/neural-computation/basic-neuro-knowledge/>Neuroscience Basic Knowledge</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/database-system/>Database System</a><ul><li><a href=/posts/database-system/database_system_1/>Database System Lecture Note 1</a></li><li><a href=/posts/database-system/database_system_2/>Database System Lecture Note 2</a></li><li><a href=/posts/database-system/database_system_3/>Database System Lecture Note 3</a></li><li><a href=/posts/database-system/database_system_4/>Database System Lecture Note 4</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/deep-learning/>DL</a><ul><li><a href=/posts/deep-learning/cnn/>Convolutional Neural Network</a></li><li><a href=/posts/deep-learning/introduction-to-deep-learning/>Introduction to Deep Learning</a></li><li><a href=/posts/deep-learning/optimizer-for-dl/>Optimization for Deep Learning</a></li><li><a href=/posts/deep-learning/rnn/>Recursive Neural Network</a></li><li><a href=/posts/deep-learning/self-attention/>Self-attention</a></li><li><a href=/posts/deep-learning/transformer/>Transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/life-learning/>Life Learning</a><ul><li><a href=/posts/life-learning/how_to_model/>how to model</a></li><li><a href=/posts/life-learning/lecture_james_mcclleland/>Lecture James McClleland</a></li><li><a href=/posts/life-learning/lecture_yao_xin/>Lecture Yao Xin</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/posts/machine-learning/>ML</a><ul class=active><li><a href=/posts/machine-learning/basic-concepts/>Basic Concepts</a></li><li><a href=/posts/machine-learning/classification/>Classification</a></li><li><a class=active href=/posts/machine-learning/decision-tree/>Decision Tree</a></li><li><a href=/posts/machine-learning/knn/>KNN</a></li><li><a href=/posts/machine-learning/perceptron/>Perceptron</a></li><li><a href=/posts/machine-learning/support-vector/>Support Vector Machines</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/operating-system/>Operating System</a><ul><li><a href=/posts/operating-system/operating_system_concepts_3/>CPU Scheduling</a></li><li><a href=/posts/operating-system/operating_system_concepts_6/>File System</a></li><li><a href=/posts/operating-system/operating_system_concepts_1/>Introduction & OS Structure</a></li><li><a href=/posts/operating-system/operating_system_concepts_7/>Mass-Storage Structure & I/O System</a></li><li><a href=/posts/operating-system/operating_system_concepts_5/>Memory Management</a></li><li><a href=/posts/operating-system/operating_system_concepts_2/>Process & Threads</a></li><li><a href=/posts/operating-system/operating_system_concepts_4/>Process Synchronization</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/posts/paper-reading/>Paper Reading</a><ul><li><a href=/posts/paper-reading/continuous_attractor_nn/>Continuous-attractor Neural Network</a></li><li><a href=/posts/paper-reading/integrated_understanding_system/>Integrated understanding system</a></li><li><a href=/posts/paper-reading/push-pull_feedback/>Push-pull feedback</a></li><li><a href=/posts/paper-reading/reservoir_decision_making/>reservoir decision making network</a></li><li><a href=/posts/paper-reading/task_representation_cognitive_tasks/>Task representations in neural networks</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(https://ztqakita.github.io/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/ztq.png><h5 class=author-name>Brandon Zhang</h5><p>March 22, 2021</p></div><div class=title><h1>Decision Tree</h1></div><div class=post-content id=post-content><h1 id=原理>原理</h1><h2 id=决策树模型与学习>决策树模型与学习</h2><p>决策树的内部节点表示一个特征或属性，叶节点表示一个类。</p><ol><li>if-then规则：互斥且完备</li><li>本质：
从训练数据集中归纳出一组分类规则（估计出条件概率模型）</li><li>损失函数：正则化的极大似然函数</li><li>学习算法：启发式方法，得到(sub-optimal)的决策树</li></ol><h3 id=一特征选择>一、特征选择</h3><p>准则：<strong>信息增益</strong></p><ol><li><p>熵：
设$X$是一个取有限个值的离散随机变量，定义为：
$$H(X) = -\sum_{i=1}^n p_i\log p_i$$</p></li><li><p>条件熵：
随机变量$X$给定的条件下随机变量$Y$的条件熵$H(Y|X)$，定义为：
$$H(Y|X) = \sum_{i=1}^np_iH(Y|X=x_i)$$
当熵和条件熵中的概率由极大似然估计得到时，分别成为经验熵和经验条件熵</p></li><li><p>信息增益：表示得知特征$X$的信息使得类$Y$的信息不确定性减少的程度。这种差值也称为互信息
$$g(D,A)=H(D)-H(D|A)$$</p></li></ol><p>特征选择方法：对训练数据集D，计算每一个特征的信息增益，选取信息增益最大的特征。</p><ol start=4><li>信息增益比
上述的特征选择存在偏向选择<strong>取值较多的特征</strong>的问题，使用information gain ratio可以解决这个问题。
定义为：
$$g_R(D, A) = \frac{g(D,A)}{H_A(D)}$$
其中，$H_A(D)=-\sum_{i=1}^n\frac{|D_i|}{D}\log_2\frac{|D_i|}{D} $，n是特征A的取值个数。</li></ol><h3 id=二决策树的生成>二、决策树的生成</h3><ol><li>ID3算法
C4.5算法的基础般，只用信息增益来选取特征。</li><li>C4.5算法
<img src=/images/posts/ML/c4.5.JPG alt></li></ol><h3 id=三决策树的剪枝>三、决策树的剪枝</h3><p>决策树的生成很容易出现过拟合现象，所以需要利用剪枝(pruning)来简化决策树。
决策树的剪枝往往通过极小化决策树整体的损失函数(loss function)来实现：
$$C_{\alpha}(T)=\sum_{i=1}^{|T|}N_tH_t(T) + \alpha|T|=C(T)+\alpha|T|$$
其中$|T|$表示树T的叶结点个数，t是树T的叶结点，该叶结点上有$N_t$个样本点，$\alpha \geq 0$为参数。</p><p>通过式子可以看出$C(T)$代表了模型对训练数据的预测误差，即拟合程度；而$\alpha|T|$代表了模型的复杂度，可以理解为正则化的方式来增强模型的泛化能力。</p><p>而树的剪枝算法分为：</p><ul><li>预剪枝：不足是基于贪心策略，带来欠拟合的风险</li><li>后剪枝</li></ul><p>后剪枝与动态规划类似，生成一棵完整的决策树以后，自底向上地对非叶节点进行考察，若剪完后损失函数变小，则进行剪枝。</p><h3 id=四cart决策树>四、CART决策树</h3><ol><li><p>回归树的生成
<img src=/images/posts/ML/CART_R.JPG alt></p></li><li><p>分类树的生成</p><ul><li>基尼系数：假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则
$$Gini(p)=\sum_{k=1}^Kp_k(1-p_k)$$
若样本集合$D$根据特征$A$是否取值$\alpha$被分割为$D_1$和$D_2$两部分，则在特征$A$下，集合$D$的基尼指数为：
$$Gini(D, A)=\frac{|D_1|}{D}Gini(D_1)+\frac{|D_2|}{D}Gini(D_2)$$
<img src=/images/posts/ML/CART_C.JPG alt></li></ul></li><li><p>剪枝
后剪枝法，从生成的决策树$T_0$开始不断剪枝，一直到根节点，形成一个子树序列${T_0, T_1, \dots, T_n}$，然后通过交叉验证法在独立的验证数据集上对子树序列进行测试。</p></li></ol></div><div class=btn-improve-page><a href=https://github.com/ztqakita/ztqakita.github.io/edit//content/posts/machine-learning/Decision-tree.md><i class="fas fa-code-branch"></i>Improve this page</a></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/machine-learning/support-vector/ class="btn btn-outline-info"><span><i class="fas fa-chevron-circle-left"></i>Prev</span><br><span>Support Vector Machines</span></a></div><div class="col-md-6 next-article"><a href=/posts/machine-learning/basic-concepts/ class="btn btn-outline-info"><span>Next <i class="fas fa-chevron-circle-right"></i></span><br><span>Basic Concepts</span></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#决策树模型与学习>决策树模型与学习</a><ul><li><a href=#一特征选择>一、特征选择</a></li><li><a href=#二决策树的生成>二、决策树的生成</a></li><li><a href=#三决策树的剪枝>三、决策树的剪枝</a></li><li><a href=#四cart决策树>四、CART决策树</a></li></ul></li></ul></nav></div></div></section></div><footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=#about>About</a></li><li class=nav-item><a class=smooth-scroll href=#skills>Skills</a></li><li class=nav-item><a class=smooth-scroll href=#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=#achievements>Achievements</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><span>Email:</span> <span>ztqakita@163.com</span></li><li><span>Phone:</span> <span>(+86)18618180071</span></li></ul></div><div class="col-md-4 col-sm-12"><p>Stay up to date with email notification</p><form><div class=form-group><input type=email class=form-control id=exampleInputEmail1 aria-describedby=emailHelp placeholder="Enter email">
<small id=emailHelp class="form-text text-muted">We'll never share your email with anyone else.</small></div><button type=submit class="btn btn-info">Submit</button></form></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=#><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png>
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/js/jquery-3.4.1.min.js></script><script src=/js/popper.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/navbar.js></script><script src=/js/main.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad()</script><script type=text/javascript async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></body></html>